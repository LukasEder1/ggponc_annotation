{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a11bef0-b53a-43b1-8115-bf2bd975b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../util')\n",
    "sys.path.insert(1, '../experiments')\n",
    "\n",
    "import os\n",
    "# Disable weights and biases (if installed)\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a1cf53c-d388-4283-9cea-3ae11f4a4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import transformers\n",
    "import datasets\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, Trainer, TrainingArguments, pipeline, DataCollatorForTokenClassification, EarlyStoppingCallback, trainer_utils\n",
    "from huggingface_utils import load_custom_dataset, LabelAligner, compute_metrics, eval_on_test_set\n",
    "from run_experiment import get_train_args\n",
    "from convert_annotations import entity_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "350ad2ba-67e9-4daa-b8c2-b415080ebd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.logging.set_verbosity_error()\n",
    "transformers.logging.disable_default_handler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9777251b-f8c6-448d-9c24-9bdf541890fa",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db7ff9c5-934c-45b2-91a6-01cf12db84e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "level = 'fine' # Change to 'coarse' to look at high-level entity classes only\n",
    "spans = 'long' # Change to 'short' to consider short spans ignoring specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0880b43-b6ee-4b3e-b46a-445ff74fb542",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_files = {\n",
    "    ('coarse' , 'short') : '01_ggponc_coarse_short.yaml',\n",
    "    ('fine', 'short') : '02_ggponc_fine_short.yaml',\n",
    "    ('coarse' , 'long' ) : '03_ggponc_coarse_long.yaml',\n",
    "    ('fine', 'long' ) : '04_ggponc_fine_long.yaml'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ca90fa-6e16-41c2-8d1e-164ce4a4222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from hydra import compose, initialize\n",
    "\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(config_path=Path('..') / 'experiments', job_name='foo')\n",
    "config = compose(config_name=config_files[(level, spans)], overrides=['cuda=0', 'link=false'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fba68f4-1216-4902-8d1c-c881b9bcacd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = config['train_dataset']\n",
    "dev_file = config['dev_dataset']\n",
    "test_file = config['test_dataset']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45224845-4d54-4877-8d46-5157eb290b7d",
   "metadata": {},
   "source": [
    "# Setup IOB-encoded dataset with train / dev / test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75372f49-e40d-4c98-9479-ea6d03b0b0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca70808ac09f4afdaa99181c8a6ecda7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset, tags = load_custom_dataset(train=train_file, dev=dev_file, test=test_file, tag_strings=config['task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "167acfe0-7690-4082-878c-cabc210eed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config['base_model_checkpoint'])\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0fbcf2e-5b4a-442b-a18f-d5992f0a5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_aligner = LabelAligner(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f94d16e1-63c9-4024-992d-1141b9637b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d704184c9b204256a1a5d53ef1e075b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7669b338dea8421989578bdf62e0f1e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b245aea5f914479a7e4c793006b5cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(lambda e: label_aligner.tokenize_and_align_labels(e, config['label_all_tokens']), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b37f9a69-b199-4974-8a1f-d07c487fff64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-Other_Finding',\n",
       " 2: 'I-Other_Finding',\n",
       " 3: 'B-Diagnosis_or_Pathology',\n",
       " 4: 'I-Diagnosis_or_Pathology',\n",
       " 5: 'B-Therapeutic',\n",
       " 6: 'I-Therapeutic',\n",
       " 7: 'B-Diagnostic',\n",
       " 8: 'I-Diagnostic',\n",
       " 9: 'B-Nutrient_or_Body_Substance',\n",
       " 10: 'I-Nutrient_or_Body_Substance',\n",
       " 11: 'B-External_Substance',\n",
       " 12: 'I-External_Substance',\n",
       " 13: 'B-Clinical_Drug',\n",
       " 14: 'I-Clinical_Drug'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = dict(enumerate(tags))\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08fcd242-41e0-420e-9fbf-2f9cdc125916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['_tags', 'attention_mask', 'fname', 'input_ids', 'labels', 'offset_mapping', 'sentence_id', 'special_tokens_mask', 'tags', 'token_type_ids', 'tokens'],\n",
       "        num_rows: 46291\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['_tags', 'attention_mask', 'fname', 'input_ids', 'labels', 'offset_mapping', 'sentence_id', 'special_tokens_mask', 'tags', 'token_type_ids', 'tokens'],\n",
       "        num_rows: 9685\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['_tags', 'attention_mask', 'fname', 'input_ids', 'labels', 'offset_mapping', 'sentence_id', 'special_tokens_mask', 'tags', 'token_type_ids', 'tokens'],\n",
       "        num_rows: 10743\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7662b9-273a-4285-8ec0-1f0354153c1a",
   "metadata": {},
   "source": [
    "# Configure and train ðŸ¤— token classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e89d59f4-5267-4023-88ab-e3ef66fa044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_experiment import get_train_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7df4091b-00c3-43c3-8407-1363f1443881",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 10 # Remove this line to train for default value of 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c73ddba2-4fd5-46a2-8dcd-ff737f2a0fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['num_train_epochs'] = num_train_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef69d25f-e0cb-424f-8f82-87fd3716b33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:run_experiment:ner_baseline\n"
     ]
    }
   ],
   "source": [
    "training_args = get_train_args(cp_path='../ner_results', run_name='ner_baseline', report_to=[], **config, resume_from_checkpoint=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37a4e392-7ac5-4276-aea0-09741f439246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def model_init():\n",
    "    return AutoModelForTokenClassification.from_pretrained(\n",
    "        config['base_model_checkpoint'],\n",
    "        num_labels=len(tags), \n",
    "        id2label=id2label,\n",
    "    )\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "tr = Trainer(\n",
    "    args=training_args,\n",
    "    model_init=model_init,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"dev\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics(tags, True),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f96996-6978-444c-bfdf-ba0f5ca7b3c4",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0264e29f-f90a-43d9-81cb-909d4ebd10eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14470' max='14470' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14470/14470 47:57, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Clinical Drug Precision</th>\n",
       "      <th>Clinical Drug Recall</th>\n",
       "      <th>Clinical Drug F1</th>\n",
       "      <th>Clinical Drug Number</th>\n",
       "      <th>Diagnosis Or Pathology Precision</th>\n",
       "      <th>Diagnosis Or Pathology Recall</th>\n",
       "      <th>Diagnosis Or Pathology F1</th>\n",
       "      <th>Diagnosis Or Pathology Number</th>\n",
       "      <th>Diagnostic Precision</th>\n",
       "      <th>Diagnostic Recall</th>\n",
       "      <th>Diagnostic F1</th>\n",
       "      <th>Diagnostic Number</th>\n",
       "      <th>External Substance Precision</th>\n",
       "      <th>External Substance Recall</th>\n",
       "      <th>External Substance F1</th>\n",
       "      <th>External Substance Number</th>\n",
       "      <th>Nutrient Or Body Substance Precision</th>\n",
       "      <th>Nutrient Or Body Substance Recall</th>\n",
       "      <th>Nutrient Or Body Substance F1</th>\n",
       "      <th>Nutrient Or Body Substance Number</th>\n",
       "      <th>Other Finding Precision</th>\n",
       "      <th>Other Finding Recall</th>\n",
       "      <th>Other Finding F1</th>\n",
       "      <th>Other Finding Number</th>\n",
       "      <th>Therapeutic Precision</th>\n",
       "      <th>Therapeutic Recall</th>\n",
       "      <th>Therapeutic F1</th>\n",
       "      <th>Therapeutic Number</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.314000</td>\n",
       "      <td>0.312082</td>\n",
       "      <td>0.535170</td>\n",
       "      <td>0.646601</td>\n",
       "      <td>0.585632</td>\n",
       "      <td>1412</td>\n",
       "      <td>0.658379</td>\n",
       "      <td>0.734192</td>\n",
       "      <td>0.694222</td>\n",
       "      <td>7069</td>\n",
       "      <td>0.637019</td>\n",
       "      <td>0.687915</td>\n",
       "      <td>0.661489</td>\n",
       "      <td>3467</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.232558</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>129</td>\n",
       "      <td>0.442396</td>\n",
       "      <td>0.595041</td>\n",
       "      <td>0.507489</td>\n",
       "      <td>484</td>\n",
       "      <td>0.497943</td>\n",
       "      <td>0.576479</td>\n",
       "      <td>0.534341</td>\n",
       "      <td>5459</td>\n",
       "      <td>0.654701</td>\n",
       "      <td>0.704014</td>\n",
       "      <td>0.678463</td>\n",
       "      <td>5855</td>\n",
       "      <td>0.602624</td>\n",
       "      <td>0.673298</td>\n",
       "      <td>0.636004</td>\n",
       "      <td>0.894012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.226000</td>\n",
       "      <td>0.296495</td>\n",
       "      <td>0.557651</td>\n",
       "      <td>0.733003</td>\n",
       "      <td>0.633415</td>\n",
       "      <td>1412</td>\n",
       "      <td>0.700743</td>\n",
       "      <td>0.746640</td>\n",
       "      <td>0.722964</td>\n",
       "      <td>7069</td>\n",
       "      <td>0.636710</td>\n",
       "      <td>0.723392</td>\n",
       "      <td>0.677289</td>\n",
       "      <td>3467</td>\n",
       "      <td>0.489130</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.407240</td>\n",
       "      <td>129</td>\n",
       "      <td>0.560484</td>\n",
       "      <td>0.574380</td>\n",
       "      <td>0.567347</td>\n",
       "      <td>484</td>\n",
       "      <td>0.517188</td>\n",
       "      <td>0.614581</td>\n",
       "      <td>0.561694</td>\n",
       "      <td>5459</td>\n",
       "      <td>0.633065</td>\n",
       "      <td>0.750811</td>\n",
       "      <td>0.686929</td>\n",
       "      <td>5855</td>\n",
       "      <td>0.617823</td>\n",
       "      <td>0.707644</td>\n",
       "      <td>0.659690</td>\n",
       "      <td>0.900326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.166000</td>\n",
       "      <td>0.321142</td>\n",
       "      <td>0.612698</td>\n",
       "      <td>0.683428</td>\n",
       "      <td>0.646133</td>\n",
       "      <td>1412</td>\n",
       "      <td>0.712123</td>\n",
       "      <td>0.752016</td>\n",
       "      <td>0.731526</td>\n",
       "      <td>7069</td>\n",
       "      <td>0.649029</td>\n",
       "      <td>0.732333</td>\n",
       "      <td>0.688169</td>\n",
       "      <td>3467</td>\n",
       "      <td>0.445652</td>\n",
       "      <td>0.317829</td>\n",
       "      <td>0.371041</td>\n",
       "      <td>129</td>\n",
       "      <td>0.563043</td>\n",
       "      <td>0.535124</td>\n",
       "      <td>0.548729</td>\n",
       "      <td>484</td>\n",
       "      <td>0.539710</td>\n",
       "      <td>0.627404</td>\n",
       "      <td>0.580263</td>\n",
       "      <td>5459</td>\n",
       "      <td>0.664970</td>\n",
       "      <td>0.736294</td>\n",
       "      <td>0.698817</td>\n",
       "      <td>5855</td>\n",
       "      <td>0.640109</td>\n",
       "      <td>0.706010</td>\n",
       "      <td>0.671447</td>\n",
       "      <td>0.901267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.116500</td>\n",
       "      <td>0.366398</td>\n",
       "      <td>0.594857</td>\n",
       "      <td>0.737252</td>\n",
       "      <td>0.658444</td>\n",
       "      <td>1412</td>\n",
       "      <td>0.721769</td>\n",
       "      <td>0.750460</td>\n",
       "      <td>0.735835</td>\n",
       "      <td>7069</td>\n",
       "      <td>0.633719</td>\n",
       "      <td>0.741563</td>\n",
       "      <td>0.683413</td>\n",
       "      <td>3467</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.294574</td>\n",
       "      <td>0.360190</td>\n",
       "      <td>129</td>\n",
       "      <td>0.618557</td>\n",
       "      <td>0.495868</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>484</td>\n",
       "      <td>0.539909</td>\n",
       "      <td>0.630702</td>\n",
       "      <td>0.581784</td>\n",
       "      <td>5459</td>\n",
       "      <td>0.660816</td>\n",
       "      <td>0.733049</td>\n",
       "      <td>0.695061</td>\n",
       "      <td>5855</td>\n",
       "      <td>0.638892</td>\n",
       "      <td>0.709110</td>\n",
       "      <td>0.672172</td>\n",
       "      <td>0.900850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.083700</td>\n",
       "      <td>0.401041</td>\n",
       "      <td>0.614788</td>\n",
       "      <td>0.730170</td>\n",
       "      <td>0.667530</td>\n",
       "      <td>1412</td>\n",
       "      <td>0.727958</td>\n",
       "      <td>0.765030</td>\n",
       "      <td>0.746034</td>\n",
       "      <td>7069</td>\n",
       "      <td>0.667712</td>\n",
       "      <td>0.736660</td>\n",
       "      <td>0.700494</td>\n",
       "      <td>3467</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.301370</td>\n",
       "      <td>129</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.549587</td>\n",
       "      <td>0.565957</td>\n",
       "      <td>484</td>\n",
       "      <td>0.563791</td>\n",
       "      <td>0.620077</td>\n",
       "      <td>0.590596</td>\n",
       "      <td>5459</td>\n",
       "      <td>0.685773</td>\n",
       "      <td>0.737660</td>\n",
       "      <td>0.710771</td>\n",
       "      <td>5855</td>\n",
       "      <td>0.659296</td>\n",
       "      <td>0.711874</td>\n",
       "      <td>0.684577</td>\n",
       "      <td>0.903114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.450769</td>\n",
       "      <td>0.613928</td>\n",
       "      <td>0.711756</td>\n",
       "      <td>0.659233</td>\n",
       "      <td>1412</td>\n",
       "      <td>0.719015</td>\n",
       "      <td>0.768143</td>\n",
       "      <td>0.742767</td>\n",
       "      <td>7069</td>\n",
       "      <td>0.653124</td>\n",
       "      <td>0.732622</td>\n",
       "      <td>0.690593</td>\n",
       "      <td>3467</td>\n",
       "      <td>0.389313</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.392308</td>\n",
       "      <td>129</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.557851</td>\n",
       "      <td>0.572034</td>\n",
       "      <td>484</td>\n",
       "      <td>0.574038</td>\n",
       "      <td>0.598644</td>\n",
       "      <td>0.586083</td>\n",
       "      <td>5459</td>\n",
       "      <td>0.683187</td>\n",
       "      <td>0.732195</td>\n",
       "      <td>0.706843</td>\n",
       "      <td>5855</td>\n",
       "      <td>0.657292</td>\n",
       "      <td>0.705801</td>\n",
       "      <td>0.680683</td>\n",
       "      <td>0.901862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.492896</td>\n",
       "      <td>0.613213</td>\n",
       "      <td>0.723088</td>\n",
       "      <td>0.663633</td>\n",
       "      <td>1412</td>\n",
       "      <td>0.736255</td>\n",
       "      <td>0.746357</td>\n",
       "      <td>0.741272</td>\n",
       "      <td>7069</td>\n",
       "      <td>0.691201</td>\n",
       "      <td>0.706951</td>\n",
       "      <td>0.698988</td>\n",
       "      <td>3467</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.394366</td>\n",
       "      <td>129</td>\n",
       "      <td>0.610738</td>\n",
       "      <td>0.564050</td>\n",
       "      <td>0.586466</td>\n",
       "      <td>484</td>\n",
       "      <td>0.540801</td>\n",
       "      <td>0.648287</td>\n",
       "      <td>0.589686</td>\n",
       "      <td>5459</td>\n",
       "      <td>0.704346</td>\n",
       "      <td>0.741759</td>\n",
       "      <td>0.722569</td>\n",
       "      <td>5855</td>\n",
       "      <td>0.661449</td>\n",
       "      <td>0.709738</td>\n",
       "      <td>0.684743</td>\n",
       "      <td>0.902040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.032400</td>\n",
       "      <td>0.521401</td>\n",
       "      <td>0.610940</td>\n",
       "      <td>0.703966</td>\n",
       "      <td>0.654163</td>\n",
       "      <td>1412</td>\n",
       "      <td>0.727773</td>\n",
       "      <td>0.767718</td>\n",
       "      <td>0.747212</td>\n",
       "      <td>7069</td>\n",
       "      <td>0.681005</td>\n",
       "      <td>0.735218</td>\n",
       "      <td>0.707074</td>\n",
       "      <td>3467</td>\n",
       "      <td>0.521277</td>\n",
       "      <td>0.379845</td>\n",
       "      <td>0.439462</td>\n",
       "      <td>129</td>\n",
       "      <td>0.630137</td>\n",
       "      <td>0.570248</td>\n",
       "      <td>0.598698</td>\n",
       "      <td>484</td>\n",
       "      <td>0.566301</td>\n",
       "      <td>0.632900</td>\n",
       "      <td>0.597751</td>\n",
       "      <td>5459</td>\n",
       "      <td>0.693469</td>\n",
       "      <td>0.745346</td>\n",
       "      <td>0.718472</td>\n",
       "      <td>5855</td>\n",
       "      <td>0.664544</td>\n",
       "      <td>0.716817</td>\n",
       "      <td>0.689691</td>\n",
       "      <td>0.903656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>0.554185</td>\n",
       "      <td>0.612394</td>\n",
       "      <td>0.713881</td>\n",
       "      <td>0.659254</td>\n",
       "      <td>1412</td>\n",
       "      <td>0.728125</td>\n",
       "      <td>0.768708</td>\n",
       "      <td>0.747867</td>\n",
       "      <td>7069</td>\n",
       "      <td>0.672200</td>\n",
       "      <td>0.735795</td>\n",
       "      <td>0.702561</td>\n",
       "      <td>3467</td>\n",
       "      <td>0.439560</td>\n",
       "      <td>0.310078</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>129</td>\n",
       "      <td>0.626450</td>\n",
       "      <td>0.557851</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>484</td>\n",
       "      <td>0.570530</td>\n",
       "      <td>0.631251</td>\n",
       "      <td>0.599356</td>\n",
       "      <td>5459</td>\n",
       "      <td>0.701301</td>\n",
       "      <td>0.745858</td>\n",
       "      <td>0.722894</td>\n",
       "      <td>5855</td>\n",
       "      <td>0.666174</td>\n",
       "      <td>0.716901</td>\n",
       "      <td>0.690607</td>\n",
       "      <td>0.903603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.579063</td>\n",
       "      <td>0.615525</td>\n",
       "      <td>0.718839</td>\n",
       "      <td>0.663182</td>\n",
       "      <td>1412</td>\n",
       "      <td>0.732114</td>\n",
       "      <td>0.770123</td>\n",
       "      <td>0.750638</td>\n",
       "      <td>7069</td>\n",
       "      <td>0.677075</td>\n",
       "      <td>0.731757</td>\n",
       "      <td>0.703355</td>\n",
       "      <td>3467</td>\n",
       "      <td>0.472527</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.390909</td>\n",
       "      <td>129</td>\n",
       "      <td>0.620370</td>\n",
       "      <td>0.553719</td>\n",
       "      <td>0.585153</td>\n",
       "      <td>484</td>\n",
       "      <td>0.568653</td>\n",
       "      <td>0.627404</td>\n",
       "      <td>0.596586</td>\n",
       "      <td>5459</td>\n",
       "      <td>0.694581</td>\n",
       "      <td>0.750811</td>\n",
       "      <td>0.721602</td>\n",
       "      <td>5855</td>\n",
       "      <td>0.666278</td>\n",
       "      <td>0.717403</td>\n",
       "      <td>0.690896</td>\n",
       "      <td>0.903887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_result = tr.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539fc922-1ab1-47e2-badb-d52f43999213",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9d4552d-4ac5-4e5f-9f2e-f794cd91ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tr.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8633db62-4834-4933-9ee4-0b4cde6f1f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.pipelines.token_classification import AggregationStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8d4df77-71ae-41f5-9833-ee7eb2e8ac13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='336' max='336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [336/336 00:13]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10743it [00:07, 1397.55it/s]\n"
     ]
    }
   ],
   "source": [
    "test_metrics = eval_on_test_set(dataset[\"test\"], tr, tokenizer, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4065841a-2cf2-4bb0-876a-d1f6b2118cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1: 0.70\n",
      " P: 0.68\n",
      " R: 0.72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "F1: {test_metrics[\"test/overall_f1\"]:.2f}\n",
    " P: {test_metrics[\"test/overall_precision\"]:.2f}\n",
    " R: {test_metrics[\"test/overall_recall\"]:.2f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca141156-6c0f-44f4-8f20-ae8cabe83089",
   "metadata": {},
   "source": [
    "### Detailed analysis of model performance\n",
    "\n",
    "See notebook: [03_NER_Analysis](03_NER_Analysis.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
