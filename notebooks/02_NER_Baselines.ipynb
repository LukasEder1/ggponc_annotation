{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a11bef0-b53a-43b1-8115-bf2bd975b701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.apppend('../util')\n",
    "sys.path.append('../experiments')\n",
    "\n",
    "import os\n",
    "# Disable weights and biases (if installed)\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a1cf53c-d388-4283-9cea-3ae11f4a4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import transformers\n",
    "import datasets\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer, Trainer, TrainingArguments, pipeline, DataCollatorForTokenClassification, EarlyStoppingCallback, trainer_utils\n",
    "from huggingface_utils import load_custom_dataset, LabelAligner, compute_metrics, eval_on_test_set\n",
    "from run_experiment import get_train_args\n",
    "from convert_annotations import entity_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "350ad2ba-67e9-4daa-b8c2-b415080ebd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.logging.set_verbosity_error()\n",
    "transformers.logging.disable_default_handler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9777251b-f8c6-448d-9c24-9bdf541890fa",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db7ff9c5-934c-45b2-91a6-01cf12db84e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "level = 'fine' # Change to 'coarse' to look at high-level entity classes only\n",
    "spans = 'long' # Change to 'short' to consider short spans ignoring specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0880b43-b6ee-4b3e-b46a-445ff74fb542",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_files = {\n",
    "    ('coarse' , 'short') : '01_ggponc_coarse_short.yaml',\n",
    "    ('fine', 'short') : '02_ggponc_fine_short.yaml',\n",
    "    ('coarse' , 'long' ) : '03_ggponc_coarse_long.yaml',\n",
    "    ('fine', 'long' ) : '04_ggponc_fine_long.yaml'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33ca90fa-6e16-41c2-8d1e-164ce4a4222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "from hydra import compose, initialize\n",
    "\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(config_path=Path('..') / 'experiments', job_name='foo')\n",
    "config = compose(config_name=config_files[(level, spans)], overrides=['cuda=0', 'link=false'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fba68f4-1216-4902-8d1c-c881b9bcacd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = config['train_dataset']\n",
    "dev_file = config['dev_dataset']\n",
    "test_file = config['test_dataset']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45224845-4d54-4877-8d46-5157eb290b7d",
   "metadata": {},
   "source": [
    "# Setup IOB-encoded dataset with train / dev / test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75372f49-e40d-4c98-9479-ea6d03b0b0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f19f8bf22d49ffb9cc9a7d19e1ca8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9eb7e7935cc43898e5c92f403ce9a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f149200e17554ddcb5f9e30d6f4670af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "711c403acacc4a01802c073f49f37f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset, tags = load_custom_dataset(train=train_file, dev=dev_file, test=test_file, tag_strings=config['task'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "167acfe0-7690-4082-878c-cabc210eed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(config['base_model_checkpoint'])\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0fbcf2e-5b4a-442b-a18f-d5992f0a5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_aligner = LabelAligner(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f94d16e1-63c9-4024-992d-1141b9637b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bb42d83117c4885858486de69501ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d99e8113aff42b7b5a01e107e93808e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3d61a80ada40daa8a8cc8da4823449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = dataset.map(lambda e: label_aligner.tokenize_and_align_labels(e, config['label_all_tokens']), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b37f9a69-b199-4974-8a1f-d07c487fff64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-Other_Finding',\n",
       " 2: 'I-Other_Finding',\n",
       " 3: 'B-Diagnosis_or_Pathology',\n",
       " 4: 'I-Diagnosis_or_Pathology',\n",
       " 5: 'B-Therapeutic',\n",
       " 6: 'I-Therapeutic',\n",
       " 7: 'B-Diagnostic',\n",
       " 8: 'I-Diagnostic',\n",
       " 9: 'B-Nutrient_or_Body_Substance',\n",
       " 10: 'I-Nutrient_or_Body_Substance',\n",
       " 11: 'B-External_Substance',\n",
       " 12: 'I-External_Substance',\n",
       " 13: 'B-Clinical_Drug',\n",
       " 14: 'I-Clinical_Drug'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = dict(enumerate(tags))\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08fcd242-41e0-420e-9fbf-2f9cdc125916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['_tags', 'attention_mask', 'fname', 'input_ids', 'labels', 'offset_mapping', 'sentence_id', 'special_tokens_mask', 'tags', 'token_type_ids', 'tokens'],\n",
       "        num_rows: 59515\n",
       "    })\n",
       "    dev: Dataset({\n",
       "        features: ['_tags', 'attention_mask', 'fname', 'input_ids', 'labels', 'offset_mapping', 'sentence_id', 'special_tokens_mask', 'tags', 'token_type_ids', 'tokens'],\n",
       "        num_rows: 12770\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['_tags', 'attention_mask', 'fname', 'input_ids', 'labels', 'offset_mapping', 'sentence_id', 'special_tokens_mask', 'tags', 'token_type_ids', 'tokens'],\n",
       "        num_rows: 13714\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7662b9-273a-4285-8ec0-1f0354153c1a",
   "metadata": {},
   "source": [
    "# Configure and train ðŸ¤— token classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e89d59f4-5267-4023-88ab-e3ef66fa044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_experiment import get_train_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7df4091b-00c3-43c3-8407-1363f1443881",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 10 # Remove this line to train for default value of 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c73ddba2-4fd5-46a2-8dcd-ff737f2a0fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "config['num_train_epochs'] = num_train_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef69d25f-e0cb-424f-8f82-87fd3716b33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:run_experiment:ner_baseline\n"
     ]
    }
   ],
   "source": [
    "training_args = get_train_args(cp_path='../ner_results', run_name='ner_baseline', report_to=[], **config, resume_from_checkpoint=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37a4e392-7ac5-4276-aea0-09741f439246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "def model_init():\n",
    "    return AutoModelForTokenClassification.from_pretrained(\n",
    "        config['base_model_checkpoint'],\n",
    "        num_labels=len(tags), \n",
    "        id2label=id2label,\n",
    "    )\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "tr = Trainer(\n",
    "    args=training_args,\n",
    "    model_init=model_init,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"dev\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics(tags, True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29759ecf-e4b4-47d1-825c-7a1f3a0acd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18600' max='18600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18600/18600 34:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Clinical Drug Precision</th>\n",
       "      <th>Clinical Drug Recall</th>\n",
       "      <th>Clinical Drug F1</th>\n",
       "      <th>Clinical Drug Number</th>\n",
       "      <th>Diagnosis Or Pathology Precision</th>\n",
       "      <th>Diagnosis Or Pathology Recall</th>\n",
       "      <th>Diagnosis Or Pathology F1</th>\n",
       "      <th>Diagnosis Or Pathology Number</th>\n",
       "      <th>Diagnostic Precision</th>\n",
       "      <th>Diagnostic Recall</th>\n",
       "      <th>Diagnostic F1</th>\n",
       "      <th>Diagnostic Number</th>\n",
       "      <th>External Substance Precision</th>\n",
       "      <th>External Substance Recall</th>\n",
       "      <th>External Substance F1</th>\n",
       "      <th>External Substance Number</th>\n",
       "      <th>Nutrient Or Body Substance Precision</th>\n",
       "      <th>Nutrient Or Body Substance Recall</th>\n",
       "      <th>Nutrient Or Body Substance F1</th>\n",
       "      <th>Nutrient Or Body Substance Number</th>\n",
       "      <th>Other Finding Precision</th>\n",
       "      <th>Other Finding Recall</th>\n",
       "      <th>Other Finding F1</th>\n",
       "      <th>Other Finding Number</th>\n",
       "      <th>Therapeutic Precision</th>\n",
       "      <th>Therapeutic Recall</th>\n",
       "      <th>Therapeutic F1</th>\n",
       "      <th>Therapeutic Number</th>\n",
       "      <th>Overall Precision</th>\n",
       "      <th>Overall Recall</th>\n",
       "      <th>Overall F1</th>\n",
       "      <th>Overall Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.284600</td>\n",
       "      <td>0.271811</td>\n",
       "      <td>0.635674</td>\n",
       "      <td>0.705804</td>\n",
       "      <td>0.668906</td>\n",
       "      <td>2257</td>\n",
       "      <td>0.693310</td>\n",
       "      <td>0.753041</td>\n",
       "      <td>0.721942</td>\n",
       "      <td>9042</td>\n",
       "      <td>0.632189</td>\n",
       "      <td>0.688016</td>\n",
       "      <td>0.658922</td>\n",
       "      <td>4122</td>\n",
       "      <td>0.422819</td>\n",
       "      <td>0.366279</td>\n",
       "      <td>0.392523</td>\n",
       "      <td>172</td>\n",
       "      <td>0.543046</td>\n",
       "      <td>0.449726</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>547</td>\n",
       "      <td>0.525882</td>\n",
       "      <td>0.552790</td>\n",
       "      <td>0.539001</td>\n",
       "      <td>6469</td>\n",
       "      <td>0.648824</td>\n",
       "      <td>0.743763</td>\n",
       "      <td>0.693057</td>\n",
       "      <td>7415</td>\n",
       "      <td>0.630842</td>\n",
       "      <td>0.687383</td>\n",
       "      <td>0.657900</td>\n",
       "      <td>0.906396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.211400</td>\n",
       "      <td>0.274428</td>\n",
       "      <td>0.640379</td>\n",
       "      <td>0.719539</td>\n",
       "      <td>0.677655</td>\n",
       "      <td>2257</td>\n",
       "      <td>0.710551</td>\n",
       "      <td>0.766423</td>\n",
       "      <td>0.737430</td>\n",
       "      <td>9042</td>\n",
       "      <td>0.629046</td>\n",
       "      <td>0.716642</td>\n",
       "      <td>0.669993</td>\n",
       "      <td>4122</td>\n",
       "      <td>0.556962</td>\n",
       "      <td>0.255814</td>\n",
       "      <td>0.350598</td>\n",
       "      <td>172</td>\n",
       "      <td>0.476812</td>\n",
       "      <td>0.601463</td>\n",
       "      <td>0.531932</td>\n",
       "      <td>547</td>\n",
       "      <td>0.547244</td>\n",
       "      <td>0.584634</td>\n",
       "      <td>0.565321</td>\n",
       "      <td>6469</td>\n",
       "      <td>0.662788</td>\n",
       "      <td>0.760486</td>\n",
       "      <td>0.708284</td>\n",
       "      <td>7415</td>\n",
       "      <td>0.642149</td>\n",
       "      <td>0.709499</td>\n",
       "      <td>0.674146</td>\n",
       "      <td>0.908050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.154600</td>\n",
       "      <td>0.290193</td>\n",
       "      <td>0.662226</td>\n",
       "      <td>0.682765</td>\n",
       "      <td>0.672339</td>\n",
       "      <td>2257</td>\n",
       "      <td>0.730948</td>\n",
       "      <td>0.749945</td>\n",
       "      <td>0.740324</td>\n",
       "      <td>9042</td>\n",
       "      <td>0.621566</td>\n",
       "      <td>0.729985</td>\n",
       "      <td>0.671427</td>\n",
       "      <td>4122</td>\n",
       "      <td>0.514851</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>172</td>\n",
       "      <td>0.528571</td>\n",
       "      <td>0.541133</td>\n",
       "      <td>0.534779</td>\n",
       "      <td>547</td>\n",
       "      <td>0.547465</td>\n",
       "      <td>0.600866</td>\n",
       "      <td>0.572924</td>\n",
       "      <td>6469</td>\n",
       "      <td>0.680358</td>\n",
       "      <td>0.759541</td>\n",
       "      <td>0.717772</td>\n",
       "      <td>7415</td>\n",
       "      <td>0.652567</td>\n",
       "      <td>0.706035</td>\n",
       "      <td>0.678249</td>\n",
       "      <td>0.908383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.340450</td>\n",
       "      <td>0.654647</td>\n",
       "      <td>0.723970</td>\n",
       "      <td>0.687566</td>\n",
       "      <td>2257</td>\n",
       "      <td>0.735212</td>\n",
       "      <td>0.753263</td>\n",
       "      <td>0.744128</td>\n",
       "      <td>9042</td>\n",
       "      <td>0.646410</td>\n",
       "      <td>0.725133</td>\n",
       "      <td>0.683512</td>\n",
       "      <td>4122</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.325581</td>\n",
       "      <td>0.375839</td>\n",
       "      <td>172</td>\n",
       "      <td>0.481013</td>\n",
       "      <td>0.555759</td>\n",
       "      <td>0.515691</td>\n",
       "      <td>547</td>\n",
       "      <td>0.546799</td>\n",
       "      <td>0.628536</td>\n",
       "      <td>0.584826</td>\n",
       "      <td>6469</td>\n",
       "      <td>0.679458</td>\n",
       "      <td>0.771274</td>\n",
       "      <td>0.722461</td>\n",
       "      <td>7415</td>\n",
       "      <td>0.654008</td>\n",
       "      <td>0.718725</td>\n",
       "      <td>0.684841</td>\n",
       "      <td>0.908707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>0.378975</td>\n",
       "      <td>0.622974</td>\n",
       "      <td>0.766504</td>\n",
       "      <td>0.687326</td>\n",
       "      <td>2257</td>\n",
       "      <td>0.723618</td>\n",
       "      <td>0.764433</td>\n",
       "      <td>0.743466</td>\n",
       "      <td>9042</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.713489</td>\n",
       "      <td>0.682367</td>\n",
       "      <td>4122</td>\n",
       "      <td>0.396825</td>\n",
       "      <td>0.290698</td>\n",
       "      <td>0.335570</td>\n",
       "      <td>172</td>\n",
       "      <td>0.535406</td>\n",
       "      <td>0.566728</td>\n",
       "      <td>0.550622</td>\n",
       "      <td>547</td>\n",
       "      <td>0.548034</td>\n",
       "      <td>0.626990</td>\n",
       "      <td>0.584859</td>\n",
       "      <td>6469</td>\n",
       "      <td>0.703560</td>\n",
       "      <td>0.732974</td>\n",
       "      <td>0.717966</td>\n",
       "      <td>7415</td>\n",
       "      <td>0.656317</td>\n",
       "      <td>0.713896</td>\n",
       "      <td>0.683896</td>\n",
       "      <td>0.907379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.405382</td>\n",
       "      <td>0.653743</td>\n",
       "      <td>0.754541</td>\n",
       "      <td>0.700535</td>\n",
       "      <td>2257</td>\n",
       "      <td>0.722981</td>\n",
       "      <td>0.772395</td>\n",
       "      <td>0.746872</td>\n",
       "      <td>9042</td>\n",
       "      <td>0.691792</td>\n",
       "      <td>0.701359</td>\n",
       "      <td>0.696543</td>\n",
       "      <td>4122</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.405063</td>\n",
       "      <td>172</td>\n",
       "      <td>0.479109</td>\n",
       "      <td>0.628885</td>\n",
       "      <td>0.543874</td>\n",
       "      <td>547</td>\n",
       "      <td>0.555172</td>\n",
       "      <td>0.622198</td>\n",
       "      <td>0.586777</td>\n",
       "      <td>6469</td>\n",
       "      <td>0.698942</td>\n",
       "      <td>0.757384</td>\n",
       "      <td>0.726990</td>\n",
       "      <td>7415</td>\n",
       "      <td>0.663588</td>\n",
       "      <td>0.720324</td>\n",
       "      <td>0.690793</td>\n",
       "      <td>0.910435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>0.447875</td>\n",
       "      <td>0.644928</td>\n",
       "      <td>0.749225</td>\n",
       "      <td>0.693175</td>\n",
       "      <td>2257</td>\n",
       "      <td>0.725029</td>\n",
       "      <td>0.773059</td>\n",
       "      <td>0.748274</td>\n",
       "      <td>9042</td>\n",
       "      <td>0.669247</td>\n",
       "      <td>0.713246</td>\n",
       "      <td>0.690546</td>\n",
       "      <td>4122</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.279070</td>\n",
       "      <td>0.332180</td>\n",
       "      <td>172</td>\n",
       "      <td>0.542744</td>\n",
       "      <td>0.499086</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>547</td>\n",
       "      <td>0.555601</td>\n",
       "      <td>0.623280</td>\n",
       "      <td>0.587498</td>\n",
       "      <td>6469</td>\n",
       "      <td>0.696446</td>\n",
       "      <td>0.761160</td>\n",
       "      <td>0.727366</td>\n",
       "      <td>7415</td>\n",
       "      <td>0.662377</td>\n",
       "      <td>0.720024</td>\n",
       "      <td>0.689999</td>\n",
       "      <td>0.909418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.484566</td>\n",
       "      <td>0.662072</td>\n",
       "      <td>0.744794</td>\n",
       "      <td>0.701001</td>\n",
       "      <td>2257</td>\n",
       "      <td>0.733375</td>\n",
       "      <td>0.784229</td>\n",
       "      <td>0.757950</td>\n",
       "      <td>9042</td>\n",
       "      <td>0.676491</td>\n",
       "      <td>0.718341</td>\n",
       "      <td>0.696788</td>\n",
       "      <td>4122</td>\n",
       "      <td>0.433071</td>\n",
       "      <td>0.319767</td>\n",
       "      <td>0.367893</td>\n",
       "      <td>172</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.559415</td>\n",
       "      <td>0.544000</td>\n",
       "      <td>547</td>\n",
       "      <td>0.561578</td>\n",
       "      <td>0.618179</td>\n",
       "      <td>0.588521</td>\n",
       "      <td>6469</td>\n",
       "      <td>0.708806</td>\n",
       "      <td>0.757653</td>\n",
       "      <td>0.732416</td>\n",
       "      <td>7415</td>\n",
       "      <td>0.671398</td>\n",
       "      <td>0.723122</td>\n",
       "      <td>0.696301</td>\n",
       "      <td>0.911331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.517462</td>\n",
       "      <td>0.664671</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.699286</td>\n",
       "      <td>2257</td>\n",
       "      <td>0.729002</td>\n",
       "      <td>0.784229</td>\n",
       "      <td>0.755608</td>\n",
       "      <td>9042</td>\n",
       "      <td>0.664149</td>\n",
       "      <td>0.725376</td>\n",
       "      <td>0.693414</td>\n",
       "      <td>4122</td>\n",
       "      <td>0.460177</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.364912</td>\n",
       "      <td>172</td>\n",
       "      <td>0.539898</td>\n",
       "      <td>0.581353</td>\n",
       "      <td>0.559859</td>\n",
       "      <td>547</td>\n",
       "      <td>0.572106</td>\n",
       "      <td>0.615087</td>\n",
       "      <td>0.592819</td>\n",
       "      <td>6469</td>\n",
       "      <td>0.706060</td>\n",
       "      <td>0.757384</td>\n",
       "      <td>0.730822</td>\n",
       "      <td>7415</td>\n",
       "      <td>0.671232</td>\n",
       "      <td>0.723122</td>\n",
       "      <td>0.696211</td>\n",
       "      <td>0.910789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>0.543252</td>\n",
       "      <td>0.663473</td>\n",
       "      <td>0.736376</td>\n",
       "      <td>0.698026</td>\n",
       "      <td>2257</td>\n",
       "      <td>0.737875</td>\n",
       "      <td>0.777372</td>\n",
       "      <td>0.757109</td>\n",
       "      <td>9042</td>\n",
       "      <td>0.667189</td>\n",
       "      <td>0.722707</td>\n",
       "      <td>0.693840</td>\n",
       "      <td>4122</td>\n",
       "      <td>0.460177</td>\n",
       "      <td>0.302326</td>\n",
       "      <td>0.364912</td>\n",
       "      <td>172</td>\n",
       "      <td>0.534031</td>\n",
       "      <td>0.559415</td>\n",
       "      <td>0.546429</td>\n",
       "      <td>547</td>\n",
       "      <td>0.564251</td>\n",
       "      <td>0.619725</td>\n",
       "      <td>0.590688</td>\n",
       "      <td>6469</td>\n",
       "      <td>0.707669</td>\n",
       "      <td>0.760351</td>\n",
       "      <td>0.733065</td>\n",
       "      <td>7415</td>\n",
       "      <td>0.672010</td>\n",
       "      <td>0.721922</td>\n",
       "      <td>0.696072</td>\n",
       "      <td>0.910819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_result = tr.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539fc922-1ab1-47e2-badb-d52f43999213",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9d4552d-4ac5-4e5f-9f2e-f794cd91ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tr.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8633db62-4834-4933-9ee4-0b4cde6f1f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.pipelines.token_classification import AggregationStrategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8d4df77-71ae-41f5-9833-ee7eb2e8ac13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='429' max='429' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [429/429 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13714it [00:05, 2515.14it/s]\n"
     ]
    }
   ],
   "source": [
    "test_metrics = eval_on_test_set(dataset[\"test\"], tr, tokenizer, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4065841a-2cf2-4bb0-876a-d1f6b2118cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1: 0.71\n",
      " P: 0.69\n",
      " R: 0.73\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "F1: {test_metrics[\"test/overall_f1\"]:.2f}\n",
    " P: {test_metrics[\"test/overall_precision\"]:.2f}\n",
    " R: {test_metrics[\"test/overall_recall\"]:.2f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca141156-6c0f-44f4-8f20-ae8cabe83089",
   "metadata": {},
   "source": [
    "### Detailed analysis of model performance\n",
    "\n",
    "See notebook: [03_NER_Analysis](03_NER_Analysis.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4c857208-9a52-4a8b-93fa-948ee9b3b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pipeline(\"ner\", model, tokenizer=tokenizer, device=0, aggregation_strategy=AggregationStrategy.FIRST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd493cdf-9b5c-45d6-9e72-b798a312ad2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'Other_Finding',\n",
       "  'score': 0.961157,\n",
       "  'word': 'perioperativen Outcome',\n",
       "  'start': 3,\n",
       "  'end': 25},\n",
       " {'entity_group': 'Diagnosis_or_Pathology',\n",
       "  'score': 0.9992925,\n",
       "  'word': 'Blutverlust',\n",
       "  'start': 27,\n",
       "  'end': 38},\n",
       " {'entity_group': 'Other_Finding',\n",
       "  'score': 0.7595823,\n",
       "  'word': 'lokale Tumorkontrolle',\n",
       "  'start': 64,\n",
       "  'end': 85},\n",
       " {'entity_group': 'Other_Finding',\n",
       "  'score': 0.6436763,\n",
       "  'word': '-',\n",
       "  'start': 111,\n",
       "  'end': 112}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p('Im perioperativen Outcome (Blutverlust, stationÃ¤rer Aufenthalt, lokale Tumorkontrolle (allerdings kurzes Follow-up von 1 Jahr) wurden keine Unterschiede festgestellt.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12c8fbe-e707-4021-a3c6-245a2933e54f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ggponc]",
   "language": "python",
   "name": "conda-env-ggponc-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
